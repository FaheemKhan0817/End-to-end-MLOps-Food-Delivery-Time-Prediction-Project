
<h1 align="center">ğŸš€ End-to-End MLOps Food Delivery Time Prediction Project ğŸ”ğŸ“¦</h1>

<p align="center">
  <img src="static/website.jpg"  alt="Project Logo"/>
</p>

<p align="center">
  <em>Predicting food delivery times using a fully automated MLOps pipeline with real-time monitoring and cloud deployment</em>
</p>

---

## ğŸ“Œ Overview

This repository contains a **production-grade MLOps pipeline** for predicting food delivery times. The project demonstrates the complete machine learning lifecycle from data preprocessing and training to deployment and monitoring, following best practices in MLOps.  
It is designed for **scalability, observability**, and **automation** using cutting-edge tools like Docker, GitHub Actions, and AWS.

---

## ğŸ§­ Project Structure

```
End-to-end-MLOps-Food-Delivery-Time-Prediction-Project/
â”œâ”€â”€ .github/                         # GitHub workflows for CI/CD
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ deploy.yml              # CI/CD pipeline for AWS deployment
â”œâ”€â”€ artifacts/                       # Model and scaler artifacts
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ model.pkl               # Trained XGBoost model
â”‚   â”‚   â””â”€â”€ scaler.pkl              # Fitted StandardScaler
â”œâ”€â”€ config/                          # Configuration files
â”‚   â””â”€â”€ paths_config.py             # Path definitions
â”œâ”€â”€ Food_Delivery_Time_Prediction.egg-info/  # Python package metadata
â”œâ”€â”€ logs/                            # Log files from app and pipeline
â”œâ”€â”€ notebooks/                       # Exploratory data analysis notebooks
â”œâ”€â”€ pipeline/                        # Training pipeline scripts
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ training_pipeline.py        # End-to-end training script
â”œâ”€â”€ src/                             # Source code
â”‚   â”œâ”€â”€ __pycache__/                # Compiled Python files
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ custom_exception.py         # Custom exception handling
â”‚   â”œâ”€â”€ data_ingestion.py           # Data loading logic
â”‚   â”œâ”€â”€ data_processing.py          # Data preprocessing logic
â”‚   â”œâ”€â”€ feature_store.py            # RedisFeatureStore for feature management
â”‚   â”œâ”€â”€ logger.py                   # Logging utility
â”‚   â””â”€â”€ model_training.py           # Model training and evaluation
â”œâ”€â”€ static/                          # Static assets for Flask app
â”‚   â””â”€â”€ favicon.ico                 # Browser favicon
â”œâ”€â”€ templates/                       # HTML templates for Flask
â”‚   â””â”€â”€ index.html                  # Main webpage
â”œâ”€â”€ tests/                           # Unit tests
â”œâ”€â”€ .gitignore                       # Git ignore file
â”œâ”€â”€ app.py                           # Flask application with prediction and drift detection
â”œâ”€â”€ docker-compose.yml               # Docker Compose for local development
â”œâ”€â”€ Dockerfile                       # Docker configuration for app
â”œâ”€â”€ instruction.md                   # Additional project instructions
â”œâ”€â”€ requirements.txt                 # Python dependencies
â””â”€â”€ setup.py                         # Project setup script
```



---

## ğŸ› ï¸ Technologies Used

- ğŸ **Python 3.10+**
- âš™ï¸ **Flask** â€“ RESTful API
- ğŸ“¦ **XGBoost** â€“ Model for regression
- ğŸ§  **Scikit-learn**, **Pandas**, **NumPy** â€“ Data wrangling & model evaluation
- ğŸ”§ **Redis** â€“ Real-time feature store
- ğŸ§ª **Alibi Detect** â€“ Data drift monitoring
- ğŸ³ **Docker** â€“ Containerization
- âœ… **GitHub Actions** â€“ CI/CD automation
- â˜ï¸ **AWS Elastic Beanstalk** â€“ Cloud deployment

---

## âš™ï¸ Setup Instructions

```bash
# 1. Clone the repo
git clone https://github.com/yourusername/End-to-end-MLOps-Food-Delivery-Time-Prediction-Project.git
cd End-to-end-MLOps-Food-Delivery-Time-Prediction-Project

# 2. Create and activate a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Run Redis locally (optional for testing)
docker run -p 6379:6379 redis

# 5. Start the Flask app
python app.py
```

---

## ğŸ§ª Training the Model

To run the full training pipeline:

```bash
python pipeline/training_pipeline.py
```

Artifacts (model, scaler) will be saved in the `artifacts/models/` directory.

---

## ğŸ” Model Monitoring

- Alibi Detect is integrated for monitoring **data drift**.
- Redis is used as a **feature store** to track incoming requests.
- Logging captures model performance and request metadata.

---

## ğŸ”„ CI/CD Pipeline

- **Trigger:** Code pushed to the `main` branch
- **Steps:** Lint â†’ Test â†’ Build Docker Image â†’ Deploy to AWS
- Defined in `.github/workflows/deploy.yml`

---

## ğŸš€ Deployment

This app is deployed on **AWS Elastic Beanstalk** using Docker.  
You can deploy it locally using:

```bash
docker build -t delivery-time-predictor .
docker run -p 5000:5000 delivery-time-predictor
```

Then go to [http://localhost:5000](http://localhost:5000) in your browser.

---

## ğŸ“„ License

This project is licensed under the MIT License.

---

## Contact

- **Author**: Faheem Khan
- **Email**: faheemthakur23@gmail.com
- **GitHub**: https://github.com/FaheemKhan0817

## ğŸ™Œ Acknowledgements

- Inspired by real-world food delivery use-cases
- Tools by Open Source communities â¤ï¸
